import pandas as pd
import numpy as np
from sklearn.preprocessing import PolynomialFeatures, StandardScaler
from sklearn.linear_model import LinearRegression, Ridge, ElasticNet
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
from sklearn.model_selection import GridSearchCV
import warnings
warnings.filterwarnings('ignore')

# Список столбцов, для которых нужно выполнить полиномиальную регрессию
blast_columns = [
    'Кол-во бласт (3ББ и выше) Z1', 
    'Кол-во бласт (3ББ и выше) Z2',
    'Кол-во бласт (3ББ и выше) Z3', 
    'Кол-во бласт (3ББ и выше) Z4',
    'Кол-во бласт (3ББ и выше) , Z5 (BN/SN)', 
    'Кол-во бласт (3ББ и выше), Z5 (1 нуклеоль)'
]

# Функция для вычисления метрик
def calculate_metrics(y_true, y_pred):
    mse = mean_squared_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)
    return mse, rmse, mae, r2

# Результаты для каждой колонки
results = {}

for col in blast_columns:
    print(f"\n{'='*70}")
    print(f"Полиномиальная регрессия для: {col}")
    print('='*70)
    
    # Обработка данных
    data_subset = quantitative_data[['Кол-во 2PN', col]].dropna()
    
    if len(data_subset) == 0:
        print("Недостаточно данных после удаления NaN значений")
        continue
    
    X = data_subset[['Кол-во 2PN']]
    y = data_subset[col]
    
    # Полиномиальные признаки (степень 2)
    poly = PolynomialFeatures(degree=2, include_bias=False)
    X_poly = poly.fit_transform(X)
    
    # Стандартизация для регуляризованных методов
    scaler = StandardScaler()
    X_poly_scaled = scaler.fit_transform(X_poly)
    
    print(f"Количество наблюдений: {len(y)}")
    print(f"Полиномиальные признаки: {poly.get_feature_names_out(['Кол-во 2PN'])}")
    
    # Результаты для текущей зависимой переменной
    results[col] = {}
    
    # 1. Обычная полиномиальная регрессия (OLS)
    print("\n1. Обычная полиномиальная регрессия (OLS):")
    
    ols_model = LinearRegression()
    ols_model.fit(X_poly, y)
    y_pred_ols = ols_model.predict(X_poly)
    mse_ols, rmse_ols, mae_ols, r2_ols = calculate_metrics(y, y_pred_ols)
    
    print(f"R²: {r2_ols:.4f}")
    print(f"RMSE: {rmse_ols:.4f}")
    print(f"MSE: {mse_ols:.4f}")
    print(f"MAE: {mae_ols:.4f}")
    print(f"Коэффициенты: {ols_model.coef_}")
    print(f"Intercept: {ols_model.intercept_:.4f}")
    
    results[col]['OLS'] = {
        'model': ols_model,
        'r2': r2_ols,
        'rmse': rmse_ols,
        'mse': mse_ols,
        'mae': mae_ols,
        'coefficients': ols_model.coef_,
        'intercept': ols_model.intercept_
    }
    
    # 2. Ridge полиномиальная регрессия (L2)
    print("\n2. Ridge полиномиальная регрессия (L2):")
    
    # Подбор оптимального параметра alpha для Ridge
    alphas_ridge = np.logspace(-3, 3, 50)
    ridge_cv = GridSearchCV(Ridge(), {'alpha': alphas_ridge}, cv=5, scoring='neg_mean_squared_error')
    ridge_cv.fit(X_poly_scaled, y)
    
    best_alpha_ridge = ridge_cv.best_params_['alpha']
    ridge_model = Ridge(alpha=best_alpha_ridge)
    ridge_model.fit(X_poly_scaled, y)
    y_pred_ridge = ridge_model.predict(X_poly_scaled)
    mse_ridge, rmse_ridge, mae_ridge, r2_ridge = calculate_metrics(y, y_pred_ridge)
    
    print(f"Лучший параметр alpha: {best_alpha_ridge:.4f}")
    print(f"R²: {r2_ridge:.4f}")
    print(f"RMSE: {rmse_ridge:.4f}")
    print(f"MSE: {mse_ridge:.4f}")
    print(f"MAE: {mae_ridge:.4f}")
    print(f"Коэффициенты: {ridge_model.coef_}")
    print(f"Intercept: {ridge_model.intercept_:.4f}")
    
    results[col]['Ridge'] = {
        'model': ridge_model,
        'alpha': best_alpha_ridge,
        'r2': r2_ridge,
        'rmse': rmse_ridge,
        'mse': mse_ridge,
        'mae': mae_ridge,
        'coefficients': ridge_model.coef_,
        'intercept': ridge_model.intercept_
    }
    
    # 3. ElasticNet полиномиальная регрессия
    print("\n3. ElasticNet полиномиальная регрессия:")
    
    # Подбор оптимальных параметров для ElasticNet
    alphas_elastic = np.logspace(-3, 2, 20)
    l1_ratios = np.linspace(0.1, 0.9, 9)
    
    elastic_cv = GridSearchCV(
        ElasticNet(max_iter=2000), 
        {'alpha': alphas_elastic, 'l1_ratio': l1_ratios}, 
        cv=5, 
        scoring='neg_mean_squared_error'
    )
    elastic_cv.fit(X_poly_scaled, y)
    
    best_alpha_elastic = elastic_cv.best_params_['alpha']
    best_l1_ratio = elastic_cv.best_params_['l1_ratio']
    elastic_model = ElasticNet(alpha=best_alpha_elastic, l1_ratio=best_l1_ratio, max_iter=2000)
    elastic_model.fit(X_poly_scaled, y)
    y_pred_elastic = elastic_model.predict(X_poly_scaled)
    mse_elastic, rmse_elastic, mae_elastic, r2_elastic = calculate_metrics(y, y_pred_elastic)
    
    print(f"Лучший параметр alpha: {best_alpha_elastic:.4f}")
    print(f"Лучший параметр l1_ratio: {best_l1_ratio:.4f}")
    print(f"R²: {r2_elastic:.4f}")
    print(f"RMSE: {rmse_elastic:.4f}")
    print(f"MSE: {mse_elastic:.4f}")
    print(f"MAE: {mae_elastic:.4f}")
    print(f"Коэффициенты: {elastic_model.coef_}")
    print(f"Intercept: {elastic_model.intercept_:.4f}")
    
    results[col]['ElasticNet'] = {
        'model': elastic_model,
        'alpha': best_alpha_elastic,
        'l1_ratio': best_l1_ratio,
        'r2': r2_elastic,
        'rmse': rmse_elastic,
        'mse': mse_elastic,
        'mae': mae_elastic,
        'coefficients': elastic_model.coef_,
        'intercept': elastic_model.intercept_
    }
    
    # 4. Сравнение коэффициентов
    print("\n4. Сравнение коэффициентов:")
    feature_names = poly.get_feature_names_out(['Кол-во 2PN'])
    print(f"{'Признак':<15} {'OLS':<12} {'Ridge':<12} {'ElasticNet':<12}")
    print("-" * 55)
    
    for i, feature in enumerate(feature_names):
        ols_coef = ols_model.coef_[i]
        ridge_coef = ridge_model.coef_[i]
        elastic_coef = elastic_model.coef_[i]
        print(f"{feature:<15} {ols_coef:<12.4f} {ridge_coef:<12.4f} {elastic_coef:<12.4f}")
    
    print(f"{'Intercept':<15} {ols_model.intercept_:<12.4f} {ridge_model.intercept_:<12.4f} {elastic_model.intercept_:<12.4f}")
    
    # 5. Лучшая модель
    models_comparison = [
        ('OLS', r2_ols, rmse_ols, mae_ols),
        ('Ridge', r2_ridge, rmse_ridge, mae_ridge),
        ('ElasticNet', r2_elastic, rmse_elastic, mae_elastic)
    ]
    
    best_model = max(models_comparison, key=lambda x: x[1])
    print(f"\n5. Лучшая модель по R²: {best_model[0]} (R² = {best_model[1]:.4f})")
    
    best_model_rmse = min(models_comparison, key=lambda x: x[2])
    print(f"   Лучшая модель по RMSE: {best_model_rmse[0]} (RMSE = {best_model_rmse[2]:.4f})")
    
    best_model_mae = min(models_comparison, key=lambda x: x[3])
    print(f"   Лучшая модель по MAE: {best_model_mae[0]} (MAE = {best_model_mae[3]:.4f})")

# Сводная таблица результатов
print(f"\n\n{'='*100}")
print("СВОДНАЯ ТАБЛИЦА РЕЗУЛЬТАТОВ ПОЛИНОМИАЛЬНОЙ РЕГРЕССИИ")
print('='*100)
print(f"{'Зависимая переменная':<35} {'Модель':<12} {'R²':<8} {'RMSE':<8} {'MAE':<8} {'Параметры'}")
print("-" * 100)

for col, col_results in results.items():
    if not col_results:
        continue
    
    for model_name, model_data in col_results.items():
        params_str = ""
        if model_name == 'Ridge':
            params_str = f"α={model_data['alpha']:.3f}"
        elif model_name == 'ElasticNet':
            params_str = f"α={model_data['alpha']:.3f}, l1={model_data['l1_ratio']:.3f}"
        
        col_name = col if model_name == 'OLS' else ''
        print(f"{col_name:<35} {model_name:<12} {model_data['r2']:<8.4f} {model_data['rmse']:<8.4f} {model_data['mae']:<8.4f} {params_str}")

print(f"\n{'='*100}")
print("ИНТЕРПРЕТАЦИЯ РЕЗУЛЬТАТОВ ПОЛИНОМИАЛЬНОЙ РЕГРЕССИИ:")
print('='*100)
print("""
ОСОБЕННОСТИ ПОЛИНОМИАЛЬНОЙ РЕГРЕССИИ:
1. Создает нелинейные зависимости (x, x²) из линейных предикторов
2. Более склонна к переобучению из-за высоких степеней
3. Коэффициенты при x² показывают кривизну зависимости

РЕГУЛЯРИЗАЦИЯ ОСОБЕННО ВАЖНА для полиномиальных моделей:
- Ridge: стабилизирует коэффициенты при высоких степенях
- ElasticNet: может исключать ненужные полиномиальные термы
- Стандартизация: обязательна для корректной работы регуляризации

ИНТЕРПРЕТАЦИЯ КОЭФФИЦИЕНТОВ:
- Положительный коэф. при x²: парабола направлена вверх
- Отрицательный коэф. при x²: парабола направлена вниз
- Коэф. при x: наклон в точке x=0

При мультиколлинеарности Ridge/ElasticNet предпочтительнее OLS!
""")
