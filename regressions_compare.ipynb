import pandas as pd
import numpy as np
import statsmodels.api as sm
from sklearn.linear_model import Ridge, ElasticNet
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import GridSearchCV
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')

# Предположим, что 'quantitative_data' - это ваш DataFrame

# Определите зависимую переменную и независимые переменные
dependent_vars = [
    'Кол-во имплант. Эмб. Z1',
    'Кол-во имплант. Эмб. Z2',
    'Кол-во имплант. Эмб. Z3',
    'Кол-во имплант. Эмб. Z4',
    'Кол-во имплант. Эмб., Z5 (BN/SN)',
    'Кол-во имплант.Эмбр., Z5 (1 нуклеоль)'
]

independent_vars = [
    'Кол-во 2PN',
    'Кол-во 2PN, Z1',
    'Кол-во 2PN, Z2',
    'Кол-во 2PN, Z3',
    'Кол-во 2PN, Z4',
    'Кол-во 2PN, Z5 (BN/SN)',
    'Кол-во 2PN, Z5 (1 нуклеоль)'
]

# Функция для вычисления метрик
def calculate_metrics(y_true, y_pred):
    mse = mean_squared_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    r2 = r2_score(y_true, y_pred)
    return mse, rmse, r2

# Результаты для каждой колонки
results = {}

for dep_var in dependent_vars:
    print(f"\n{'='*60}")
    print(f"Анализ для: {dep_var}")
    print('='*60)
    
    # Выбираем зависимую переменную
    y = quantitative_data[dep_var]
    
    # Выбираем независимые переменные
    X = quantitative_data[independent_vars]
    
    # Удаляем NaN значения из X и y
    combined_data = pd.concat([X, y], axis=1).dropna()
    
    # Обновляем X и y, чтобы индексы совпадали
    X_clean = combined_data[independent_vars]
    y_clean = combined_data[dep_var]
    
    if len(X_clean) == 0:
        print("Недостаточно данных после удаления NaN значений")
        continue
    
    # Результаты для текущей зависимой переменной
    results[dep_var] = {}
    
    # 1. Обычная линейная регрессия (OLS)
    print("\n1. Обычная линейная регрессия (OLS):")
    X_ols = sm.add_constant(X_clean)
    model_ols = sm.OLS(y_clean, X_ols).fit()
    y_pred_ols = model_ols.predict(X_ols)
    mse_ols, rmse_ols, r2_ols = calculate_metrics(y_clean, y_pred_ols)
    
    print(f"R²: {r2_ols:.4f}")
    print(f"RMSE: {rmse_ols:.4f}")
    print(f"MSE: {mse_ols:.4f}")
    
    results[dep_var]['OLS'] = {
        'model': model_ols,
        'r2': r2_ols,
        'rmse': rmse_ols,
        'mse': mse_ols
    }
    
    # 2. Ridge регрессия (L2 регуляризация)
    print("\n2. Ridge регрессия (L2 регуляризация):")
    
    # Подбор оптимального параметра alpha для Ridge
    alphas_ridge = np.logspace(-3, 2, 50)  # от 0.001 до 100
    ridge_cv = GridSearchCV(Ridge(), {'alpha': alphas_ridge}, cv=5, scoring='neg_mean_squared_error')
    ridge_cv.fit(X_clean, y_clean)
    
    best_alpha_ridge = ridge_cv.best_params_['alpha']
    ridge_model = Ridge(alpha=best_alpha_ridge)
    ridge_model.fit(X_clean, y_clean)
    y_pred_ridge = ridge_model.predict(X_clean)
    mse_ridge, rmse_ridge, r2_ridge = calculate_metrics(y_clean, y_pred_ridge)
    
    print(f"Лучший параметр alpha: {best_alpha_ridge:.4f}")
    print(f"R²: {r2_ridge:.4f}")
    print(f"RMSE: {rmse_ridge:.4f}")
    print(f"MSE: {mse_ridge:.4f}")
    
    results[dep_var]['Ridge'] = {
        'model': ridge_model,
        'alpha': best_alpha_ridge,
        'r2': r2_ridge,
        'rmse': rmse_ridge,
        'mse': mse_ridge
    }
    
    # 3. ElasticNet регрессия
    print("\n3. ElasticNet регрессия:")
    
    # Подбор оптимальных параметров для ElasticNet
    alphas_elastic = np.logspace(-3, 1, 20)
    l1_ratios = np.linspace(0.1, 0.9, 9)
    
    elastic_cv = GridSearchCV(
        ElasticNet(max_iter=2000), 
        {'alpha': alphas_elastic, 'l1_ratio': l1_ratios}, 
        cv=5, 
        scoring='neg_mean_squared_error'
    )
    elastic_cv.fit(X_clean, y_clean)
    
    best_alpha_elastic = elastic_cv.best_params_['alpha']
    best_l1_ratio = elastic_cv.best_params_['l1_ratio']
    elastic_model = ElasticNet(alpha=best_alpha_elastic, l1_ratio=best_l1_ratio, max_iter=2000)
    elastic_model.fit(X_clean, y_clean)
    y_pred_elastic = elastic_model.predict(X_clean)
    mse_elastic, rmse_elastic, r2_elastic = calculate_metrics(y_clean, y_pred_elastic)
    
    print(f"Лучший параметр alpha: {best_alpha_elastic:.4f}")
    print(f"Лучший параметр l1_ratio: {best_l1_ratio:.4f}")
    print(f"R²: {r2_elastic:.4f}")
    print(f"RMSE: {rmse_elastic:.4f}")
    print(f"MSE: {mse_elastic:.4f}")
    
    results[dep_var]['ElasticNet'] = {
        'model': elastic_model,
        'alpha': best_alpha_elastic,
        'l1_ratio': best_l1_ratio,
        'r2': r2_elastic,
        'rmse': rmse_elastic,
        'mse': mse_elastic
    }
    
    # 4. Сравнение коэффициентов
    print("\n4. Сравнение коэффициентов:")
    print(f"{'Переменная':<25} {'OLS':<10} {'Ridge':<10} {'ElasticNet':<12}")
    print("-" * 60)
    
    # OLS коэффициенты (исключаем константу)
    ols_coefs = model_ols.params[1:]  # исключаем intercept
    ridge_coefs = ridge_model.coef_
    elastic_coefs = elastic_model.coef_
    
    for i, var in enumerate(independent_vars):
        print(f"{var:<25} {ols_coefs.iloc[i]:<10.4f} {ridge_coefs[i]:<10.4f} {elastic_coefs[i]:<12.4f}")
    
    # 5. Лучшая модель
    models_comparison = [
        ('OLS', r2_ols, rmse_ols),
        ('Ridge', r2_ridge, rmse_ridge),
        ('ElasticNet', r2_elastic, rmse_elastic)
    ]
    
    # Сортируем по R² (по убыванию) и по RMSE (по возрастанию)
    best_model = max(models_comparison, key=lambda x: x[1])
    print(f"\n5. Лучшая модель по R²: {best_model[0]} (R² = {best_model[1]:.4f})")
    
    best_model_rmse = min(models_comparison, key=lambda x: x[2])
    print(f"   Лучшая модель по RMSE: {best_model_rmse[0]} (RMSE = {best_model_rmse[2]:.4f})")

# Сводная таблица результатов
print(f"\n\n{'='*80}")
print("СВОДНАЯ ТАБЛИЦА РЕЗУЛЬТАТОВ")
print('='*80)
print(f"{'Зависимая переменная':<35} {'Модель':<12} {'R²':<8} {'RMSE':<10} {'Параметры'}")
print("-" * 80)

for dep_var, dep_results in results.items():
    if not dep_results:
        continue
    
    for model_name, model_data in dep_results.items():
        params_str = ""
        if model_name == 'Ridge':
            params_str = f"α={model_data['alpha']:.3f}"
        elif model_name == 'ElasticNet':
            params_str = f"α={model_data['alpha']:.3f}, l1={model_data['l1_ratio']:.3f}"
        
        print(f"{dep_var if model_name == 'OLS' else '':<35} {model_name:<12} {model_data['r2']:<8.4f} {model_data['rmse']:<10.4f} {params_str}")

print(f"\n{'='*80}")
print("ИНТЕРПРЕТАЦИЯ РЕЗУЛЬТАТОВ:")
print('='*80)
print("""
1. OLS (Обычная линейная регрессия): Базовая модель без регуляризации
2. Ridge (L2): Уменьшает коэффициенты, но не обнуляет их. Хорошо при мультиколлинеарности
3. ElasticNet: Комбинация L1 и L2 регуляризации. Может обнулять коэффициенты и группировать коррелированные переменные

Параметры:
- α (alpha): сила регуляризации (больше = больше штраф)
- l1_ratio: баланс между L1 и L2 (0 = только L2, 1 = только L1)

Выбор модели: обычно лучшая по R² или наименьшая по RMSE, учитывая интерпретируемость
""")
